---
title: "Chapter 6-7 Overfitting"
author: "Stephen R. Proulx"
date: "4/28/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#library(tidyverse)
#library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#library(brms)

#library(rethinking)
```


```{r}
## R code 7.1
sppnames <- c( "afarensis","africanus","habilis","boisei",
    "rudolfensis","ergaster","sapiens")
brainvolcc <- c( 438 , 452 , 612, 521, 752, 871, 1350 )
masskg <- c( 37.0 , 35.5 , 34.5 , 41.5 , 55.5 , 61.0 , 53.5 )
d <- data.frame( species=sppnames , brain=brainvolcc , mass=masskg )
```


```{r}
## R code 7.2
d$mass_std <- (d$mass - mean(d$mass))/sd(d$mass)
d$brain_std <- d$brain / max(d$brain)
```


```{r model 1}
# linear model where brain size is trying to fit, body mass is trying ro predict
## R code 7.3
m7.1 <- quap(
    alist(
        brain_std ~ dnorm( mu , exp(log_sigma) ), # statistical modle that brain size is fit around this parameter with some sd
        mu <- a + b*mass_std, # linear model.  mean of normal depends on intercept that relies on mass
        a ~ dnorm( 0.5 , 1 ), # prior
        b ~ dnorm( 0 , 10 ), # prior
        log_sigma ~ dnorm( 0 , 1 ) # prior, sd has to be positive, exponetially transform
        # posteriro for parameters is normally distributed
    ), data=d )
```



Run the other polynomial models
- each of these just add extra terms for polynomial
```{r fit_polys model 2}
## R code 7.7
m7.2 <- quap(
    alist(
        brain_std ~ dnorm( mu , exp(log_sigma) ),
        mu <- a + b[1]*mass_std + b[2]*mass_std^2, # slopes are written as vector
        a ~ dnorm( 0.5 , 1 ),
        b ~ dnorm( 0 , 10 ),
        log_sigma ~ dnorm( 0 , 1 )
    ), data=d , start=list(b=rep(0,2)) )

## R code 7.8
m7.3 <- quap(
    alist(
        brain_std ~ dnorm( mu , exp(log_sigma) ),
        mu <- a + b[1]*mass_std + b[2]*mass_std^2 +
                  b[3]*mass_std^3,
        a ~ dnorm( 0.5 , 1 ),
        b ~ dnorm( 0 , 10 ),
        log_sigma ~ dnorm( 0 , 1 )
    ), data=d , start=list(b=rep(0,3)) )

m7.4 <- quap(
    alist(
        brain_std ~ dnorm( mu , exp(log_sigma) ),
        mu <- a + b[1]*mass_std + b[2]*mass_std^2 +
                  b[3]*mass_std^3 + b[4]*mass_std^4,
        a ~ dnorm( 0.5 , 1 ),
        b ~ dnorm( 0 , 10 ),
        log_sigma ~ dnorm( 0 , 1 )
    ), data=d , start=list(b=rep(0,4)) )

m7.5 <- quap(
    alist(
        brain_std ~ dnorm( mu , exp(log_sigma) ),
        mu <- a + b[1]*mass_std + b[2]*mass_std^2 +
                  b[3]*mass_std^3 + b[4]*mass_std^4 +
                  b[5]*mass_std^5,
        a ~ dnorm( 0.5 , 1 ),
        b ~ dnorm( 0 , 10 ),
        log_sigma ~ dnorm( 0 , 1 )
    ), data=d , start=list(b=rep(0,5)) )


## R code 7.9
# fits for all species, no variance of distribution
# instead of fitting you add small number
m7.6 <- quap(
    alist(
        brain_std ~ dnorm( mu , 0.001 ),
        mu <- a + b[1]*mass_std + b[2]*mass_std^2 +
                  b[3]*mass_std^3 + b[4]*mass_std^4 +
                  b[5]*mass_std^5 + b[6]*mass_std^6,
        a ~ dnorm( 0.5 , 1 ),
        b ~ dnorm( 0 , 10 )
    ), data=d , start=list(b=rep(0,6)) )
```


Let's view some of the fits
```{r plot curves}
## R code 7.10
post <- extract.samples(m7.1) # linear model
mass_seq <- seq( from=min(d$mass_std) , to=max(d$mass_std) , length.out=100 )
l <- link( m7.1 , data=list( mass_std=mass_seq ) )
mu <- apply( l , 2 , mean )
ci <- apply( l , 2 , PI )
plot( brain_std ~ mass_std , data=d )
lines( mass_seq , mu )
shade( ci , mass_seq )


post <- extract.samples(m7.3) # 3rd order model
mass_seq <- seq( from=min(d$mass_std) , to=max(d$mass_std) , length.out=100 )
l <- link( m7.3 , data=list( mass_std=mass_seq ) )
mu <- apply( l , 2 , mean )
ci <- apply( l , 2 , PI )
plot( brain_std ~ mass_std , data=d )
lines( mass_seq , mu )
shade( ci , mass_seq )

```



We can calculate the lppd, which is really just calculating the likelihood of each individual datapoint. Points with higher values are being better fit by the model. Since the fitted model is maximizing the posterior probability of the parameters, it is averaging across all the data points. This means that a model that fits 90% of the data pretty well and one datapoint poorly is more favorable than a model that fits 100% of the data moderately well. Most of the datapoints are simillarly well fit, but humans stand out as being more poorly fit. 
```{r}
# measure of average likelihoodgiven the model 
# averaging in two ways
## R code 7.13
set.seed(1)
lppd( m7.1 , n=1e4 ) # lppd command provides list of data point from set, ech number are the average divergence
# for each element of posterior 
# mcmc fitting is list of parameters, each value of parameter we calculate the likelihood of seeing data
# treat each data point as an independent draw
# as long as your model is multiple likelihood of different data points
# if you dont cause they arent independent, this wouldn't make sense, can't treat them as sepete data points cause of covariane
# tells us avaerage likeihood each data point that are log trasnformed
# continuous distribution, probabliy density isnt constrained between 1-0
#discrete: pron of mass <1

# the bigger the umber, the more likeli to see that data point
# - number means much smaller liklihood
# maximizing the likelihood of whole dataset
# linear fit model doesn't fit humans well
# total diverge ce of the model is the average of all the likelihood datapoints, 
```


Now do this long-hand to get a better sense of where the numbers come from. This uses the sim function to extract the log-likelihood of the data for a large number of posterior parameter values and then averages and log transforms it. 
```{r}
set.seed(1)
logprob <- sim( m7.1 , ll=TRUE , n=1e4) %>% as_tibble()%>% mutate_all(exp)  # sim simulates posterior data and sample from sampling distribution, however ll= TRUE just reports log likelihood from samples from posterior 
# out is a matrix that is column (likelihood of each sample) for each data point
 
logprob_sum <- summarise_all(logprob,mean)

(logprob_sum<-mutate_all(logprob_sum,log))

# we want liklihood given the parameters
```

Now lets do it in more detail for just a couple of the data points. We'll pick the first species in the list and humans (species 7). Here we first pull 10^4 samples from the posterior and then use the formula for the linear fit to find the likelihood. The numbers are identical to the prior calculation because we used the same random seed. 
```{r}
set.seed(1)
post <- extract.samples(m7.1,n=1e4)

# unblack box what happens in this simulated call
lpdd1 <-  mutate(post,sigma=exp(log_sigma)) %>%
  mutate(lik = dnorm(d$brain_std[1],mean = a+b* d$mass_std[1], sd=sigma, log=FALSE)) %>% # calculate likelihood, what is the likelihood of data point 1, probab density of seeing outcome size sd size of sp. 1 given mean and sd
  summarise(mean=mean(lik),n=n()) %>% mutate(lppd = log(mean))

lpdd7 <-  mutate(post,sigma=exp(log_sigma)) %>%
  mutate(lik = dnorm(d$brain_std[7],mean = a+b* d$mass_std[7], sd=sigma, log=FALSE)) %>%
  summarise(mean=mean(lik),n=n()) %>% mutate(lppd = log(mean))

c(lpdd1$lppd,lpdd7$lppd) 

# summarize by taking mean and taking it back to log sclae

```


And now lets look at individual calculations for a single set of parameters from the posterior. Each posterios sample is quirky in it's own way. Some do fit the humans better (although almost none of them will fit humans better than the other species). 
```{r}
# show how indiviudal parameters relate back to 
(pars=post[1,]) # picked parameter set from 1

lpdd_example <- mutate(d, lik = dnorm(brain_std,mean = pars$a+pars$b* mass_std, sd=exp(pars$log_sigma), log=FALSE)) %>% mutate(log_lik = log(lik))

lpdd_example
# human data set is more poorly fit than normal
# some draws fit better than others for human 
# evaluate aggregate is averaging all those values

(pars=post[5,])# picked parameter set from 5

lpdd_example <- mutate(d, lik = dnorm(brain_std,mean = pars$a+pars$b* mass_std, sd=exp(pars$log_sigma), log=FALSE)) %>% mutate(log_lik = log(lik))

lpdd_example

```



```{r}
## R code 7.14
set.seed(1)
logprob <- sim( m7.1 , ll=TRUE , n=1e4 )
n <- ncol(logprob)
ns <- nrow(logprob)
f <- function( i ) log_sum_exp( logprob[,i] ) - log(ns)
( lppd <- sapply( 1:n , f ) )
```


Now we want to calculate the lppd for each of the models, over all of their posterior samples. lppd does the wprk of averaging over the posterior and the datapoints. 
```{r}
# if we calculate that, the one with more parameters are better forsure, are we warrented in adding those parameters?
## R code 7.15
set.seed(1)
sapply( list(m7.1,m7.2,m7.3,m7.4,m7.5,m7.6) , function(m) sum(lppd(m)) ) # applies fxn, to all 6 of models in sequence, then takes sum
```


```{r}
## R code 7.16
#modified to use the multi-core argument

# out of sequence computations are expensive and take forever, don't run this code
# goes through and generates data sets and does sim training test where it leaves one out at a time
N <- 20
kseq <- 1:5
dev <- sapply( kseq , function(k) {
        print(k);
        r <- mcreplicate( 1e2 , sim_train_test( N=N, k=k ) , mc.cores = 8);
        c( mean(r[1,]) , mean(r[2,]) , sd(r[1,]) , sd(r[2,]) )
    } )
```



```{r}

# look at out of sample devergence,
# minimum at 3 parametres, this is how the data was created so that makes sense
# complexity of the model goes up
## R code 7.18
plot( 1:5 , dev[1,] , ylim=c( min(dev[1:2,])-5 , max(dev[1:2,])+10 ) ,
    xlim=c(1,5.1) , xlab="number of parameters" , ylab="deviance" ,
    pch=16 , col=rangi2 )
mtext( concat( "N = ",N ) )
points( (1:5)+0.1 , dev[2,] )
for ( i in kseq ) {
    pts_in <- dev[1,i] + c(-1,+1)*dev[3,i]
    pts_out <- dev[2,i] + c(-1,+1)*dev[4,i]
    lines( c(i,i) , pts_in , col=rangi2 )
    lines( c(i,i)+0.1 , pts_out )
}
```
