---
title: "Lec 4 - Linear Models"
author: "sbsambado"
date: "4/14/2020"
output: html_document
---

Lecture video by Richard McElreath from his Statistical Rethinking textbook 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Recreating plot from Lec 3
```{r}
# R code 4.42

data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18,] # all adults

# define average weight, x-bar
xbar <- mean(d2$weight)

# fit model
m4.3 <- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu <- a + b*(weight - xbar), # log posterior
    a ~ dnorm(178, 20),
    b ~ dlnorm(0,1),
    sigma ~ dunif(0, 50)
  ),
  data = d2)
# R.code 4.44
precis(m4.3)

plot(height ~ weight, data = d2, col = rangi2)
post <- extract.samples(m4.3)
a_map <- mean(post$a)
b_map <- mean(post$b)
curve(a_map + b_map*(x - xbar), add = TRUE)
```

Showing uncertainty
- want to get uncertainty onto the graph
- sample from posterior
  - use mean and sd to approximate posterior
  - sample from multivariate normal distribution of parameters
  - use samples to generate predictions that integrate over the uncertainty
```{r}
# R. code 4.47

post <- extract.samples(m4.3)
post[1:5,]

# posterior is full of lines
# certainty at the ends is broader than the certainty at the means

## predict mu

# R code 4.50
post <- extract.samples(m4.3)
mu_at_50 <- post$a + post$b * ( 50 - xbar) # fix mu at 50

## predict every mu
# want a distribution for every value of x
# R code 4.54
# define seq of weights to compute predictions for these values will be on the horiz axis
weight.seq <- seq(25, 70, 1)

# use link to compute mu for each sample from posterior
# and for each weight in weight.seq
mu <- link(m4.3, data = data.frame(weight = weight.seq))
str(mu) 


```

How `link` works
- sample from posterior
- define series of predictor (weight) values
- for each predictor value
  - for each sample from posterior
    - compute mu : a + b*(weight - xbar)
- summarize

```{r}
# R code 4.58

post <- extract.samples(m4.3)
mu.link <- function(weight) post$a + post$b*(weight - xbar)
weight.seq <- seq(25, 70, 1)
mu <- sapply(weight.seq, mu.link) # essentially a loop
mu.mean <- apply(mu, 2, mean) # takes 2nd dimension of column mu, and calculates the mean
mu.HPDI <- apply(mu, 2, HPDI, prob = 0.89)
```

Nothing special about 95% uncertainty, interested in shape and not boundaries

Curves from linear
- Linear models can make curves
- Polynomial regression
  - common, badly behaved
- Splines
  - very flexible, highly geocentric
  
Polynomial and splines are not mechanistic.

Polynomial Regression
- purely descriptive (geocentric) strategy: use polynomial of predictor variable
    1st order (line): mui = alpha + beta1*xi
    2nd order (parabola): alpha + beta1*xi + beta2(xi^2)
    
Standardize predictors
-very helpful to standarize priors

to standardize:
- subtract mean
- divde by sd
- result: mean of 0 and a sd of 1

- every parameter acts on parabola shape (splines don't have this problem)

Polynomial grief
- polynomial make absurd predictions outside range of data
- parameter influence every part of curve, so hard to understand
- not actually very flexible - can't have a monotonic curve

- geometric models aren't bad, just have to know how to use them

* Spline*

Going local - B-splines
- basis-splines: wiggly function built from many local, less wiggly functions
- basis function: a local function
- better than polynomials, but equally geocentrix
- Bayesian b-splines often called p-spines


B-splines
- linear models, but with some weird synthetic variables
- weights, w, are like slopes
- basis functions b are synthetic variables
  - in spirit like a squared or cubed terms
  - but observed data not used to build b
  - b values turn on weights in different regions of x variables
  
```{r}
# B-spline of climate

# climate data is wiggly
library(rethinking)
data(cherry_blossoms)
d <- cherry_blossoms
precis(d)
```
B-spline of climate
- recipe
  - choose some knots - lcoations on predictor variables wehre the spline is anchored
  - choose degree of basis functions - how wiggly
  - find posterior distribution of weights
  
~ more knots mean more wiggle in global function

Weights
- just an ordinary linear model now
- basis functions in a matrix B

```{r}
# R code 4.76

m4.7 <- quap(
  alist(
    T ~ dnorm(mu, sigma),
    mu <- a + B %*% w,
    a ~ dnorm(6,10)
    w ~ dnorm(0,1),
    sigma ~ dexp(1)
  ),
  data = list(T = d2$temp, B = B),
  start = list(w = rep(0, ncol(B)))
)
```

Spline possibilities
- knots an dbasis degree are choices
- must worry about overfitting data
- all splines are descriptive, not mechanistic